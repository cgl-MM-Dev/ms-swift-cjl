# Swift SFT å®Œæ•´è®­ç»ƒé…ç½®æ–‡ä»¶ - æ”¯æŒ Wandb å’Œç¯å¢ƒå˜é‡
# åŸºäºå®˜æ–¹æ–‡æ¡£çš„æ‰€æœ‰å‚æ•°ï¼ŒåŒ…å«è¯¦ç»†æ³¨é‡Šå’Œå€™é€‰å€¼

# ==============================
# ğŸ”¥ åŸºæœ¬å‚æ•° (Basic Parameters)
# ==============================

tuner_backend: peft  # å¯é€‰: 'peft', 'unsloth'ã€‚é»˜è®¤ä¸º'peft'
train_type: full     # å¯é€‰: 'lora', 'full', 'longlora', 'adalora', 'llamapro', 'adapter', 'vera', 'boft', 'fourierft', 'reft'
adapters: []         # é€‚é…å™¨è·¯å¾„åˆ—è¡¨ï¼Œé»˜è®¤ä¸º[]
external_plugins: [] # å¤–éƒ¨æ’ä»¶æ–‡ä»¶åˆ—è¡¨ï¼Œé»˜è®¤ä¸º[]
seed: 42            # éšæœºç§å­ï¼Œé»˜è®¤ä¸º42

# ==============================
# ğŸ”¥ æ¨¡å‹å‚æ•° (Model Parameters)
# ==============================

model: /workspace/ckpt-tmp-1/Qwen2_5-VL-7B-Instruct
model_type: qwen2_5_vl  # å¸¸è§: qwen2_5_vl, qwen2_vl, glm4v, internvl2, llava
torch_dtype: bfloat16   # å¯é€‰: 'float16', 'bfloat16', 'float32'
attn_impl: flash_attn   # å¯é€‰: 'sdpa', 'eager', 'flash_attention_2', 'flash_attn'

# ==============================
# ğŸ”¥ æ•°æ®å‚æ•° (Data Parameters)
# ==============================

dataset: /workspace/Dataset/v0a/v0a.yaml
val_dataset: []                 # éªŒè¯é›†ï¼Œé»˜è®¤ä¸º[]
split_dataset_ratio: 0.         # éªŒè¯é›†åˆ†å‰²æ¯”ä¾‹
dataset_num_proc: 4             # æ•°æ®é¢„å¤„ç†è¿›ç¨‹æ•°
load_from_cache_file: true      # æ˜¯å¦ä½¿ç”¨ç¼“å­˜
dataset_shuffle: true           # è®­ç»ƒé›†æ‰“ä¹±
# val_dataset_shuffle: false    # éªŒè¯é›†æ‰“ä¹±
remove_unused_columns: true     # åˆ é™¤æœªä½¿ç”¨çš„åˆ—

# ==============================
# ğŸ”¥ è®­ç»ƒå‚æ•° (Training Parameters)
# ==============================

num_train_epochs: 3                # è®­ç»ƒè½®æ•°
per_device_train_batch_size: 1     # æ¯è®¾å¤‡è®­ç»ƒæ‰¹æ¬¡å¤§å°
per_device_eval_batch_size: 1      # æ¯è®¾å¤‡éªŒè¯æ‰¹æ¬¡å¤§å°
learning_rate: 1e-6                # å­¦ä¹ ç‡
gradient_accumulation_steps: 8     # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
warmup_ratio: 0.05                 # é¢„çƒ­æ¯”ä¾‹
dataloader_num_workers: 4          # æ•°æ®åŠ è½½è¿›ç¨‹æ•°

# ä¼˜åŒ–å™¨è®¾ç½®
optim: adamw_torch              # å¯é€‰: 'adamw_torch', 'adamw_hf', 'sgd'
lr_scheduler_type: cosine       # å¯é€‰: 'linear', 'cosine', 'polynomial'
# lr_scheduler_kwargs:
#   min_lr: 5e-6                # transformers çš„ cosine scheduler ä¸æ”¯æŒæ­¤å‚æ•°
weight_decay: 0.01              # æƒé‡è¡°å‡
max_grad_norm: 1.0              # æ¢¯åº¦è£å‰ª

# ==============================
# ğŸ”¥ LoRAå‚æ•° (LoRA Parameters)
# ==============================
lora_configs:
  lora_rank: 8                    # LoRA rank
  lora_alpha: 32                  # LoRA alpha
  lora_dropout: 0.05              # LoRA dropout
  target_modules: all-linear      # ç›®æ ‡æ¨¡å—
  use_dora: false                 # æ˜¯å¦ä½¿ç”¨DoRA
  use_rslora: false               # æ˜¯å¦ä½¿ç”¨RS-LoRA
  lorap_lr_ratio: null            # LoRA+å‚æ•°ï¼Œå»ºè®®10~16

# ==============================
# ğŸ”¥ å¤šæ¨¡æ€å‚æ•° (Multimodal Parameters)
# ==============================

max_length: 24576               # æœ€å¤§åºåˆ—é•¿åº¦
max_pixels: 200704              # æœ€å¤§å›¾åƒåƒç´ æ•°
freeze_vit: true                # å†»ç»“è§†è§‰ç¼–ç å™¨
padding_free: false             # æ— å¡«å……è®­ç»ƒ

# ==============================
# ğŸ”¥ æ¨¡æ¿å‚æ•° (Template Parameters)
# ==============================

template: null                  # å¯¹è¯æ¨¡æ¿ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹©
system: null                    # è‡ªå®šä¹‰systemæç¤º
truncation_strategy: delete     # æˆªæ–­ç­–ç•¥: 'delete', 'left', 'right'
use_chat_template: true         # ä½¿ç”¨chatæ¨¡æ¿
template_backend: swift         # æ¨¡æ¿åç«¯: 'swift', 'jinja'

# ==============================
# ğŸ”¥ æŸå¤±å‡½æ•° (Loss Parameters)
# ==============================

# loss_type: default              # å¯é€‰: 'None', 'graph_loss', 'focal_loss'
# loss_scale: default             # æŸå¤±æƒé‡: 'last_round', 'all'

# ==============================
# ğŸ”¥ è¾“å‡ºå’Œæ—¥å¿— (Output & Logging)
# ==============================

output_dir: ./output
logging_steps: 5                # æ—¥å¿—è®°å½•é—´éš”
# eval_steps: 500               # è¯„ä¼°é—´éš”
save_strategy: epoch            # ä¿å­˜çš„ç­–ç•¥ 'no'ã€'steps'ã€'epoch'ï¼Œé»˜è®¤ä¸º'steps'
# save_steps: 1000                # ä¿å­˜é—´éš”
save_only_model: true           # åªä¿å­˜æ¨¡å‹æƒé‡
save_total_limit: 5             # ä¿å­˜æ•°é‡é™åˆ¶
report_to: wandb                # æ—¥å¿—åç«¯: 'tensorboard', 'wandb', 'none'

# ==============================
# ğŸ”¥ Wandbé…ç½® (Wandb Configuration)
# ==============================

wandb_project: cjl_sft_tmp-2        # Wandbé¡¹ç›®å (å¿…å¡«)
wandb_run_name: qwen2_5-vl-7b-full-lr-1e-6-v0a-tmp     # å®éªŒè¿è¡Œåç§° (å¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ)
wandb_tags: ["qwen2.5-vl", "lora", "sft", "complete-config"]  # å®éªŒæ ‡ç­¾

# å¸¸ç”¨wandbé…ç½®ç¤ºä¾‹:
# wandb_project: "my_multimodal_sft"
# wandb_run_name: "qwen2_5_vl_lora_rank16_lr2e5"
# wandb_tags: ["multimodal", "vision-language", "fine-tuning"]

# ==============================
# ğŸ”¥ DeepSpeedé…ç½® (DeepSpeed)
# ==============================

deepspeed: zero2                # å¯é€‰: 'zero1', 'zero2', 'zero3', JSONæ–‡ä»¶è·¯å¾„

# ==============================
# ğŸ”¥ ç‰¹å®šæ¨¡å‹å‚æ•° (Model-specific Parameters)
# ==============================

model_kwargs:
#   # Qwen2.5-VL ç‰¹å®šå‚æ•°
#   # fps_max_frames: 768           # è§†é¢‘æœ€å¤§å¸§æ•°
#   # fps_min_frames: 4             # è§†é¢‘æœ€å°å¸§æ•°
#   # video_max_pixels: 128000      # è§†é¢‘æœ€å¤§åƒç´ æ•°
#   # min_pixels: 256               # å›¾ç‰‡æœ€å°åƒç´ æ•°
max_pixels: 12845056  # 16384 * 28 * 28     # å›¾ç‰‡æœ€å¤§åƒç´ æ•°

# å…¶ä»–æ¨¡å‹çš„ model_kwargs ç¤ºä¾‹:
# GLM-4V:
# model_kwargs:
#   max_length: 8192
#   temperature: 0.8
#
# InternVL2:
# model_kwargs:
#   dynamic_image_size: true
#   use_thumbnail: true

# ==============================
# ğŸ”¥ ç¯å¢ƒå˜é‡é…ç½® (Environment Variables)
# ==============================

env_vars:
  # Wandb ç›¸å…³ç¯å¢ƒå˜é‡
  WANDB_BASE_URL: "https://wandb.glm.ai/"
  WANDB_API_KEY: "local-d70dccc058669955f0ae6b6d655fbb52b9a994ee"
  WANDB_ENTITY: "garygedegege"
  
  # GPU è®¾ç½® (å¯é€‰ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè®¾ç½®)
  CUDA_VISIBLE_DEVICES: "4,5,6,7"      # ä½¿ç”¨å‰4å¼ å¡
  NPROC_PER_NODE: "4"                  # æ¯ä¸ªèŠ‚ç‚¹4ä¸ªè¿›ç¨‹
  
  # è®­ç»ƒä¼˜åŒ–ç›¸å…³ç¯å¢ƒå˜é‡
  CUDA_DEVICE_MAX_CONNECTIONS: "1"
  PYTORCH_CUDA_ALLOC_CONF: "expandable_segments:True"
  PYTHONWARNINGS: "ignore"
  # Qwen2.5-VL ç‰¹å®šå‚æ•° (é€šè¿‡ç¯å¢ƒå˜é‡ä¼ é€’ï¼Œé¿å… JSON é—®é¢˜)
  # MAX_PIXELS: "12845056"               # å›¾ç‰‡æœ€å¤§åƒç´ æ•°
  
  # ç¼“å­˜ç›¸å…³ (å¯é€‰)
  # HF_HUB_CACHE: "/path/to/hf_cache"
  # TRANSFORMERS_CACHE: "/path/to/transformers_cache"
  
  # é‡è¦è¯´æ˜ï¼šæ¨¡å‹ç‰¹å®šå‚æ•° (å¦‚ Qwen2.5-VL çš„ fps_max_frames, video_max_pixels)
  # è¯·ä½¿ç”¨ä¸Šé¢çš„ model_kwargs å­—æ®µè®¾ç½®ï¼Œä¸è¦åœ¨ç¯å¢ƒå˜é‡ä¸­é‡å¤è®¾ç½®
  # 
  # åŒºåˆ«è¯´æ˜ï¼š
  # - model_kwargs: ç›´æ¥ä¼ é€’ç»™æ¨¡å‹æ„é€ å‡½æ•°çš„å‚æ•° (æ¨è)
  # - ç¯å¢ƒå˜é‡: è¢«æŸäº›æ¨¡å‹ä»£ç åœ¨è¿è¡Œæ—¶è¯»å–çš„ç³»ç»Ÿçº§è®¾ç½®
  # 
  # å¯¹äº Qwen2.5-VLï¼Œä¸¤ç§æ–¹å¼éƒ½æ”¯æŒï¼Œä½†æˆ‘ä»¬ç»Ÿä¸€ä½¿ç”¨ model_kwargs æ–¹å¼

# ç¯å¢ƒå˜é‡è¯´æ˜:
# - æ‰€æœ‰å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸²æ ¼å¼
# - ç¯å¢ƒå˜é‡ä¼šåœ¨è®­ç»ƒå¼€å§‹å‰è®¾ç½®
# - ä¼˜å…ˆçº§: env_vars > è„šæœ¬é»˜è®¤å€¼ > ç³»ç»Ÿç¯å¢ƒå˜é‡
# - æ”¯æŒè¦†ç›– model_kwargs ä¸­çš„å‚æ•°

# ==============================
# ğŸ”¥ é«˜çº§å‚æ•° (Advanced Parameters)
# ==============================

# æ•°æ®ç›¸å…³
streaming: false                # æµå¼æ•°æ®é›†
packing: false                  # æ•°æ®packing
lazy_tokenize: null             # å»¶è¿Ÿtokenize
cached_dataset: []              # ç¼“å­˜æ•°æ®é›†è·¯å¾„

# è®­ç»ƒç­–ç•¥
fp16: false                     # ä½¿ç”¨FP16
bf16: true                      # ä½¿ç”¨BF16 (æ ¹æ®torch_dtypeè‡ªåŠ¨è®¾ç½®)
tf32: null                      # ä½¿ç”¨TF32

# æ£€æŸ¥ç‚¹ç›¸å…³
resume_from_checkpoint: null    # æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹
load_best_model_at_end: false   # åŠ è½½æœ€ä½³æ¨¡å‹
create_checkpoint_symlink: false # åˆ›å»ºè½¯é“¾æ¥

# é¢„æµ‹å’Œç”Ÿæˆ
predict_with_generate: false    # éªŒè¯æ—¶ä½¿ç”¨ç”Ÿæˆæ¨¡å¼

# å…¨å‚æ•°è®­ç»ƒç›¸å…³
freeze_parameters: []           # å†»ç»“å‚æ•°å‰ç¼€
freeze_parameters_regex: null   # å†»ç»“å‚æ•°æ­£åˆ™
trainable_parameters: []       # å¯è®­ç»ƒå‚æ•°å‰ç¼€

# Hubç›¸å…³
push_to_hub: false              # æ¨é€åˆ°Hub
hub_model_id: null              # Hubæ¨¡å‹ID
use_hf: false                   # ä½¿ç”¨HuggingFace

# å…¶ä»–
ddp_timeout: 18000000           # DDPè¶…æ—¶æ—¶é—´
ddp_backend: null               # DDPåç«¯
ignore_args_error: false       # å¿½ç•¥å‚æ•°é”™è¯¯

# ==============================
# ä½¿ç”¨è¯´æ˜å’Œç¤ºä¾‹
# ==============================

# è¿™æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å‚æ•°çš„å®Œæ•´é…ç½®æ–‡ä»¶æ¨¡æ¿
# 
# å¿«é€Ÿå¼€å§‹:
# 1. ä¿®æ”¹ model è·¯å¾„ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
# 2. ä¿®æ”¹ dataset è·¯å¾„ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„
# 3. ä¿®æ”¹ output_dir ä¸ºä½ çš„è¾“å‡ºç›®å½•
# 4. è®¾ç½® wandb ç›¸å…³å‚æ•°
# 5. æ ¹æ®éœ€è¦è°ƒæ•´å…¶ä»–å‚æ•°
#
# ä½¿ç”¨æ–¹å¼:
# bash submit_swift_sft.sh configs/swift_sft_complete.yaml
#
# å‚æ•°è¦†ç›–ç¤ºä¾‹:
# bash submit_swift_sft.sh configs/swift_sft_complete.yaml --learning_rate 2e-5 --lora_rank 16
#
# æ³¨æ„äº‹é¡¹:
# - ğŸ”¥ æ ‡è®°çš„å‚æ•°æ˜¯é‡è¦å‚æ•°ï¼Œæ–°æ‰‹ç”¨æˆ·åº”é‡ç‚¹å…³æ³¨
# - ç¯å¢ƒå˜é‡é€šè¿‡ env_vars å­—æ®µç»Ÿä¸€ç®¡ç†
# - wandb é…ç½®æ”¯æŒå®Œå…¨è‡ªå®šä¹‰é¡¹ç›®åå’Œå®éªŒå
# - æ‰€æœ‰å‚æ•°éƒ½æœ‰è¯¦ç»†æ³¨é‡Šå’Œå€™é€‰å€¼è¯´æ˜
